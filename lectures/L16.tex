\documentclass[11pt]{article}
\usepackage{listings}
\usepackage{tikz}
\usepackage{url}
%\usepackage{algorithm2e}
\usetikzlibrary{arrows,automata,shapes,positioning}
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=2.5em, text centered, rounded corners, minimum height=2em]
\tikzstyle{bw} = [rectangle, draw, fill=blue!20, 
    text width=3.5em, text centered, rounded corners, minimum height=2em]

\newcommand{\handout}[5]{
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { {\bf ECE459: Programming for Performance } \hfill #2 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #5  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\em #3 \hfill #4} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\newcommand{\lecture}[4]{\handout{#1}{#2}{#3}{#4}{Lecture #1}}
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
%\renewcommand{\baselinestretch}{1.25}

\begin{document}

\lecture{16 --- February 9, 2015}{Winter 2015}{Patrick Lam}{version 0}

Following Gove, we'll parallelize the following code:
{\tiny
\begin{lstlisting}[language=C,numbers=left]
#include <stdlib.h>

void setup(double *vector, int length) {
    int i;
    for (i = 0; i < length; i++)
    {
	vector[i] += 1.0;
    }
}

int main()
{
    double *vector;
    vector = (double*) malloc (sizeof (double) * 1024 * 1024);
    for (int i = 0; i < 1000; i++)
    {
	setup (vector, 1024*1024);
    }
}
\end{lstlisting}
}

\paragraph{Automatic Parallelization.} Let's first see what compilers can do automatically.
The Solaris Studio compiler yields the following output:
{\small 
\begin{verbatim}
$ cc -O3 -xloopinfo -xautopar omp_vector.c 
"omp_vector.c", line 5: PARALLELIZED, and serial version generated
"omp_vector.c", line 15: not parallelized, call may be unsafe
\end{verbatim}
} 

{\bf Note:} The Solaris compiler generates two versions of the code,
and decides, at runtime, if the parallel code would be faster, depending on
whether the loop bounds, at runtime, are large enough to justify spawning
threads.

Under the hood, most parallelization frameworks use {\tt OpenMP},
which we'll see next time. For now, you can control the number of
threads with the {\tt OMP\_NUM\_THREADS} environment variable.

\paragraph{Autoparallelization in {\tt gcc}.} 
{\tt gcc} 4.3+ can also parallelize loops, but there are a couple of
problems: 1) the loop parallelization doesn't seem very stable yet; 2)
I can't figure out how to make {\tt gcc} tell you what it did in a comprehensible
way (you can try {\tt -fdump-tree-parloops-details}); and,
perhaps most importantly for performance, 3) {\tt gcc} doesn't have
many heuristics yet for guessing which loops are profitable (since 4.8, it can
use profiling data and tries to infer the number of loop iterations
happen)\footnote{\url{https://gcc.gnu.org/wiki/AutoParInGCC}}.

{\tt clang} also has the {\tt polly} parallelization framework, but I couldn't
figure out how to try it.

One way to inspect {\tt gcc}'s output is by giving it the {\tt
  -S} option and looking at the resulting assembly code yourself. This
is obviously not practical for production software.
\begin{verbatim}
$ gcc -std=c99 omp_vector.c -O2 -floop-parallelize-all -ftree-parallelize-loops=2 -S           
\end{verbatim}

\newpage
The resulting {\tt .s} file contains the following code:
{ \tiny
\begin{verbatim}
        call    GOMP_parallel_start
        movl    %edi, (%esp)
        call    setup._loopfn.0
        call    GOMP_parallel_end
\end{verbatim}
} {\tt gcc} code appears to ignore \verb+OMP_NUM_THREADS+.  Here's
some potential output from a parallelized program: { \tiny
\begin{verbatim}
        $ export OMP_NUM_THREADS=2
        $ time ./a.out
        real	0m5.167s
        user	0m7.872s
        sys	0m0.016s
\end{verbatim}
}
(When you use multiple (virtual) CPUs, CPU usage can increase beyond
100\% in {\tt top}, and real time can be less than user time in
the {\tt time} output, since user time counts the time used by all CPUs.)

Let's look at some gcc examples from: \url{http://gcc.gnu.org/wiki/AutoparRelated}.

\paragraph{Loops That gcc's Automatic Parallelization Can Handle.}~\\

  Single loop:
  \begin{lstlisting}
for (i = 0; i < 1000; i++)
    x[i] = i + 3;
  \end{lstlisting}

  Nested loops with simple dependency:
  \begin{lstlisting}
for (i = 0; i < 100; i++)
    for (j = 0; j < 100; j++)
        X[i][j] = X[i][j] + Y[i-1][j];
  \end{lstlisting}

  Single loop with not-very-simple dependency:
  \begin{lstlisting}
for (i = 0; i < 10; i++)
    X[2*i+1] = X[2*i];
  \end{lstlisting}

\paragraph{Loops That gcc's Automatic Parallelization Can't Handle.}~\\

  Single loop with if statement:
  \begin{lstlisting}
for (j = 0; j <= 10; j++)
    if (j > 5) X[i] = i + 3;
  \end{lstlisting}

  Triangle loop:
  \begin{lstlisting}
for (i = 0; i < 100; i++)
    for (j = i; j < 100; j++)
        X[i][j] = 5;
  \end{lstlisting}

  \newpage
\paragraph{Manual Parallelization.} Let's first think about how we could 
manually parallelize this code.
\begin{itemize}
\item {\bf Option 1:} horizontal, \begin{minipage}{7em} --- --- --- ---\\[-.8em] --- --- --- ---\\[-.8em] --- --- --- --- \end{minipage} \\
Create 4 threads; each thread does 1000 iterations on its own sub-array.

\item {\bf Option 2:} bad horizontal, \begin{minipage}{7em} --- --- --- ---\\[-.8em] --- --- --- ---\\[-.8em] --- --- --- --- \end{minipage} \\
1000 times, create 4 threads which each operate once on the sub-array.

\item {\bf Option 3:} vertical $ \quad \: \qquad \mid \mid \mid\mid \:\: \mid \mid \mid \mid \:\: \mid \mid \mid \mid\:\: \mid \mid \mid \mid$\\
Create 4 threads; for each element, the owning thread does 1000 iterations on that element.
\end{itemize}
We can try these and empirically see which works better. As you might expect, bad horizontal
does the worst. Horizontal does best. See L11 notes for benchmark results and further discussion.

\subsection*{Case study: Multiplying a Matrix by a Vector.}
Next, we'll see how automatic parallelization does on a more complicated
program. We will progressively remove barriers to parallelization for
this program:

{\tiny
\begin{lstlisting}[language=C,numbers=left]
void matVec (double **mat, double *vec, double *out,
             int *row, int *col) 
{
  int i, j;
  for (i = 0; i < *row; i++)
  {
    out[i] = 0;
    for (j = 0; j < *col; j++)
    {
      out[i] += mat[i][j] * vec[j];
    }
  }
}
\end{lstlisting}
}

The Solaris C compiler refuses to parallelize this code:
{\small 
\begin{verbatim}
$ cc -O3 -xloopinfo -xautopar fploop.c 
"fploop.c", line 5: not parallelized, not a recognized for loop
"fploop.c", line 8: not parallelized, not a recognized for loop
\end{verbatim} 
}
For definitive documentation about Sun's automatic parallelization, see
Chapter 10 of their \emph{Fortran Programming Guide} and do the analogy to C:

\url{http://download.oracle.com/docs/cd/E19205-01/819-5262/index.html}

In this case, the loop bounds are not constant, and the write to {\tt
  out} might overwrite either {\tt row} or {\tt col}. So, let's modify
the code and make the loop bounds {\tt int}s rather than {\tt int *}s.

{\tiny
\begin{lstlisting}[language=C,numbers=left]
void matVec (double **mat, double *vec, double *out,
             int row, int col) 
{
  int i, j;
  for (i = 0; i < row; i++)
  {
    out[i] = 0;
    for (j = 0; j < col; j++)
    {
      out[i] += mat[i][j] * vec[j];
    }
  }
}
\end{lstlisting}
}
\newpage This changes the error message:
{\small 
\begin{verbatim}
$ cc -O3 -xloopinfo -xautopar fploop1.c 
"fploop1.c", line 5: not parallelized, unsafe dependence
"fploop1.c", line 8: not parallelized, unsafe dependence
\end{verbatim} 
}
Now the problem is that {\tt out} might alias {\tt mat} or {\tt vec};
as I've mentioned previously, parallelizing
in the presence of aliases could change the run-time behaviour.

\paragraph{{\tt restrict} qualifier.} 
Recall that the {\tt restrict} qualifier on pointer {\tt p} tells
the compiler\footnote{\url{http://cellperformance.beyond3d.com/articles/2006/05/demystifying-the-restrict-keyword.html}} that it may assume that, in the scope of {\tt p},
the program will not use any other pointer {\tt q} to access the
data at {\tt *p}.

{\tiny
\begin{lstlisting}[language=C,numbers=left]
void matVec (double **mat, double *vec, double * restrict out,
             int row, int col) 
{
  int i, j;
  for (i = 0; i < row; i++)
  {
    out[i] = 0;
    for (j = 0; j < col; j++)
    {
      out[i] += mat[i][j] * vec[j];
    }
  }
}
\end{lstlisting}
}

Now Solaris {\tt cc} is happy to parallelize the outer loop:

{\small 
\begin{verbatim}
$ cc -O3 -xloopinfo -xautopar fploop2.c 
"fploop2.c", line 5: PARALLELIZED, and serial version generated
"fploop2.c", line 8: not parallelized, unsafe dependence
\end{verbatim} 
}

There's still a dependence in the inner loop. This dependence is because
all inner loop iterations write to the same location, {\tt out[i]}. We'll
discuss that problem below.

In any case, the outer loop is the one that can actually improve performance,
since parallelizing it imposes much less barrier synchronization cost 
waiting for all threads to finish. So, even if we tell the compiler to ignore
the reduction issue, it will generally refuse to parallelize inner loops:
{\small 
\begin{verbatim}
$ cc -g -O3 -xloopinfo -xautopar -xreduction fploop2.c 
"fploop2.c", line 5: PARALLELIZED, and serial version generated
"fploop2.c", line 8: not parallelized, not profitable
\end{verbatim} 
}

\paragraph{Summary of conditions for automatic parallelization.} Here's what I 
can figure out; you may also refer to Chapter 3 of the Solaris Studio
\emph{C User's Guide}, but it doesn't spell out the exact conditions
either. To parallelize a loop, it must:
\begin{itemize}
\item have a recognized loop style, e.g. {\tt for} loops with
bounds that don't vary per iteration;
\item have no dependencies between data accessed in loop bodies for
  each iteration;
\item not conditionally change scalar variables read after the loop
  terminates, or change any scalar variable across iterations;
\item have enough work in the loop body to make parallelization profitable.
\end{itemize}

\paragraph{Reductions.} The concept behind a 
reduction (as made ``famous'' in MapReduce, which we'll talk about
later) is reducing a set of data to a smaller set which somehow
summarizes the data. For us, reductions are going to reduce
arrays to a single value. Consider, for instance, this function, which
calculates the sum of an array of numbers:

{\tiny
\begin{lstlisting}[language=C,numbers=left]
double sum (double *array, int length)
{
  double total = 0;

  for (int i = 0; i < length; i++)
    total += array[i];
  return total;
}
\end{lstlisting}
}

There are two barriers: 1) the value of {\tt total} depends on what
gets computed in previous iterations; and 2) addition is actually
non-associative for floating-point values. ({\sf Why? When is it
appropriate to parallelize non-associative operations?})

Nevertheless, the Solaris C compiler will explicitly recognize
some reductions and can parallelize them for you:

{\small
\begin{verbatim}
$ cc -O3 -xautopar -xreduction -xloopinfo sum.c
"sum.c", line 5: PARALLELIZED, reduction, and serial version generated
\end{verbatim}
}

{\bf Note:}  If we try to do the reduction on {\tt fploop.c} with {\tt restrict}s added, we'll get the following:

\begin{lstlisting}
$ cc -O3 -xautopar -xloopinfo  -xreduction -c fploop.c
"fploop.c", line 5: PARALLELIZED, and serial version generated
"fploop.c", line 8: not parallelized, not profitable
\end{lstlisting}

\paragraph{Dealing with function calls.} Generally, function calls
can have arbitrary side effects. Production compilers will usually
avoid parallelizing loops with function calls; research compilers try
to ensure that functions are pure and then parallelize them.
(This is why functional languages are nice for parallel
programming: impurity is visible in type signatures.)

For builtin functions, like {\tt sin()}, you can promise to the 
compiler that you didn't replace them with your own implementations
({\tt -xbuiltin}), and then the compiler will parallelize the loop.

Another option is to crank up the optimization level ({\tt -xO4}), or
to explicitly tell the compiler to inline certain functions ({\tt
  -xinline=}), thereby enabling parallelization. This doesn't work as
well as one might hope; using macros will always work, but is less maintainable.

\paragraph{Helping the compiler parallelize.} Let's summarize what we've
seen. To help the compiler, we can use the {\tt restrict} qualifier on
pointers (possibly copying a pointer to a {\tt restrict}-qualified
pointer: {\tt int * restrict p = s->p;}); and, we can make sure that
loop bounds don't change in the loop (e.g. by using temporary
variables). Some compilers can automatically create different versions
for the alias-free case and the (parallelized) aliased case; at
runtime, the program runs the aliased case if the inputs permit.


\end{document}
