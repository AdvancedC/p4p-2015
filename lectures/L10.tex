\documentclass[11pt]{article}
\usepackage{listings}
\usepackage{tikz}
\usepackage{url}
\usepackage{hyperref}
%\usepackage{algorithm2e}
\usetikzlibrary{arrows,automata,shapes,positioning}
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=2.5em, text centered, rounded corners, minimum height=2em]
\tikzstyle{bw} = [rectangle, draw, fill=blue!20, 
    text width=3.5em, text centered, rounded corners, minimum height=2em]

\newcommand{\handout}[5]{
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { {\bf ECE459: Programming for Performance } \hfill #2 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #5  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\em #3 \hfill #4} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\lstset{basicstyle=\ttfamily \scriptsize}

\newcommand{\lecture}[4]{\handout{#1}{#2}{#3}{#4}{Lecture #1}}
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
%\renewcommand{\baselinestretch}{1.25}

% http://gurmeet.net/2008/09/20/latex-tips-n-tricks-for-conference-papers/
\newcommand{\squishlist}{
 \begin{list}{$\bullet$}
  { \setlength{\itemsep}{0pt}
     \setlength{\parsep}{3pt}
     \setlength{\topsep}{3pt}
     \setlength{\partopsep}{0pt}
     \setlength{\leftmargin}{1.5em}
     \setlength{\labelwidth}{1em}
     \setlength{\labelsep}{0.5em} } }
\newcommand{\squishlisttwo}{
 \begin{list}{$\bullet$}
  { \setlength{\itemsep}{0pt}
     \setlength{\parsep}{0pt}
    \setlength{\topsep}{0pt}
    \setlength{\partopsep}{0pt}
    \setlength{\leftmargin}{2em}
    \setlength{\labelwidth}{1.5em}
    \setlength{\labelsep}{0.5em} } }
\newcommand{\squishend}{
\end{list}  }
\newtheorem{example}{Example}


\begin{document}

\lecture{10 --- January 26, 2015}{Winter 2015}{Patrick Lam}{version 1}

\section*{C++ atomics}
We've talked about locks. Atomics are a lower-overhead alternative to
locks as long as you're doing suitable operations.

We are only going to talk about atomics with sequential consistency.
If you use
the default {\tt std::memory\_order}, that's what you get.

{\bf Don't use relaxed atomics unless you're an expert!\footnote{\url{http://stackoverflow.com/questions/9553591/c-stdatomic-what-is-stdmemory-order-and-how-to-use-them}}}

\paragraph{Key idea.}
An \emph{atomic operation} is indivisible.
Other threads see state before or after the operation,
nothing in between.

\paragraph{atomic flags.} The simplest form of C++11 atomic is the {\tt atomic\_flag}.
Not surprisingly, this represents a boolean flag. You can clear the flag and test-and-set it.

\begin{lstlisting}[language=C++]
#include <atomic>

atomic_flag f = ATOMIC_FLAG_INIT;
int foo() {
  f.clear();
  if (f.test_and_set()) {
    // was true
  }
}
\end{lstlisting}

{\tt test\_and\_set} atomically sets the flag to true, and returns the previous value. 
There is no assignment (=) operator for {\tt atomic\_flag}s.

\paragraph{More general C++ atomics.} Boolean flags are nice, but we want more.
C++11 supports arbitrary types as atomic. Here'a an example declaration:
\begin{lstlisting}
#include <atomic>

atomic<int> x;
\end{lstlisting}
The C++11 library implements atomics using lock-free operations for small types
and using mutexes for large types.

The general types of operations that you can do with atomics are three: reads, writes, and
RMW (read-modify-write) operations. C++ has syntax to make these all transparent.

\begin{lstlisting}[language=C++]
// atomic reads and writes
#include <atomic>
#include <iostream>

std::atomic<int> ai;
int i;

int main() {
    ai = 4;
    i = ai;
    ai = i;
    std::cout << i;
}
\end{lstlisting}
If you want, you can also use {\tt i = ai.load()} and {\tt ai.store(i)}.

As for RMW operations, consider {\tt ai++}. This is really

~~~{\tt tmp = ai.read(); tmp++; ai.write(tmp); }

But, hardware can do that atomically. It can also do other RMWs: {\tt +-, \&=, etc, compare-and-swap}.

More info on C++11 atomics:\\
\url{http://preshing.com/20130618/atomic-vs-non-atomic-operations/}

\section*{The Compiler and You}
Making the compiler work for you is critical to programming for
performance. We'll therefore see some compiler implementation details
in this class. Understanding these details will help you reason about
how your code gets translated into machine code and thus executed.

\paragraph{Three Address Code.} Compiler analyses are much easier to
perform on simple expressions which have two operands and a
result---hence three addresses---rather than full expression trees.
Any good compiler will therefore convert a program's abstract syntax
tree into an intermediate, portable, three-address code before going
to a machine-specific backend.

Each statement represents one fundamental operation; we'll consider
these operations to be atomic. A typical statement looks like this:

\[ \qquad \mbox{result} := \mbox{operand$_1$}\:\mbox{operator}\:\mbox{operand$_2$} \]

Three-address code is useful for reasoning about data races. It is
also easier to read than assembly, as it separates out memory reads
and writes.

\paragraph{GIMPLE: gcc's three-address code.} To see the GIMPLE representation 
of your code, pass {\tt gcc} the {\tt -fdump-tree-gimple} flag. You
can also see all of the three address code generated by the compiler;
use {\tt -fdump-tree-all}. You'll probably just be interested in the
optimized version.  

I suggest using GIMPLE to reason about your code at a low level
without having to read assembly.


\subsection*{Branch Prediction}
We've mentioned before that modern CPUs must rely on branch
prediction to get the performance we're used to. We also had a
live coding demo which demonstrated the impact of mis-prediction.
Here's a bit more information about providing the compiler with
branch prediction hints.

The right thing to do most of the time is to not call it. Use
profile-guided optimization whenever possible if you do want to use
branch prediction. Nevertheless, providing branch prediction hints
can be useful for error cases on slow processors.

{\tt gcc} provides a builtin function:

    \verb+     long __builtin_expect (long exp, long c)+

\noindent
When you call it, you are indicating that the expected result is that
{\tt exp} equals {\tt c}. In response, the compiler will pass the prediction
on to the CPU and reorder the code properly to take advantage of the
(hopefully correct) hint.

\subsection*{The {\tt restrict} qualifier} 
The {\tt restrict} qualifier on pointer {\tt p} tells
the compiler\footnote{\url{http://cellperformance.beyond3d.com/articles/2006/05/demystifying-the-restrict-keyword.html}} that it may assume that, in the scope of {\tt p},
the program will not use any other pointer {\tt q} to access the
data at {\tt *p}.

The {\tt restrict} qualifier is a feature introduced in C99: ``The
restrict type qualifier allows programs to be written so that
translators can produce significantly faster executables.''
  \begin{itemize}
    \item To request C99 in {\tt gcc}, use the {\tt -std=c99} flag.
  \end{itemize}

{\tt restrict} means: you are promising the
compiler that the pointer will never alias (another pointer will not
point to the same data) for the lifetime of the pointer.  Hence, two
pointers declared {\tt restrict} must never point to the same data.

An example from Wikipedia:
\begin{lstlisting}
  void updatePtrs(int* ptrA, int* ptrB, int* val) {
    *ptrA += *val;
    *ptrB += *val;
  }
\end{lstlisting}
Would declaring all these pointers as {\tt restrict} generate better code?

Well, let's look at the GIMPLE.

\begin{lstlisting}[numbers=left]
void updatePtrs(int* ptrA, int* ptrB, int* val) {
 D.1609 = *ptrA;
 D.1610 = *val;
 D.1611 = D.1609 + D.1610;
 *ptrA = D.1611;
 D.1612 = *ptrB;
 D.1610 = *val;
 D.1613 = D.1612 + D.1610;
 *ptrB = D.1613;
}
\end{lstlisting}

Now we can answer the question: ``Could any operation be left out if
all the pointers didn't overlap?''

\begin{itemize}
\item If {\tt ptrA} and {\tt val} are not equal, you don't have to
      reload the data on {\bf line 7}.
\item Otherwise, you would: there might be a call, somewhere:\\\verb+    updatePtrs(&x, &y, &x);+
\end{itemize}

Hence, this set of annotations allows optimization:
\begin{lstlisting}
    void updatePtrs(int* restrict ptrA, 
                    int* restrict ptrB,
                    int* restrict val)
\end{lstlisting}
Note: you can get the optimization by just declaring {\tt ptrA} and
      {\tt val} as {\tt restrict}; {\tt ptrB} isn't needed for this optimization

\paragraph{Summary of {\tt restrict}.}
Use {\tt restrict} whenever you know the pointer will not alias
another pointer (also declared {\tt restrict}).

It's hard for the compiler to infer pointer aliasing information;
it's easier for you to specify it. If the compiler has this information,
it can better optimize your code; in the body of a critical loop, that
can result in better performance.

A caveat: don't lie to the compiler, or you will get undefined behaviour.

Aside: {\tt restrict} is not the same as {\tt const}. {\tt const} data can still be
changed through an alias.

\end{document}
